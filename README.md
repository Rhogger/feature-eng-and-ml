# Feature Engineering and Machine Learning Project üé¨üìä

Projeto completo de Feature Engineering e Machine Learning aplicado √† an√°lise de filmes usando a API do TMDb (The Movie Database). O projeto implementa um pipeline completo desde a coleta de dados at√© o treinamento de modelos de classifica√ß√£o.

## üìã Pr√©-requisitos

- Python 3.12 ou superior
- Git
- Pipenv ou venv (para gerenciamento de depend√™ncias)
- Chave de API do TMDb (gratuita)

## ‚ú® Tecnologias Utilizadas

- **Python 3.12** - Linguagem principal
- **Pandas** - Manipula√ß√£o e an√°lise de dados
- **NumPy** - Computa√ß√£o cient√≠fica
- **Scikit-learn** - Machine Learning
- **Matplotlib & Seaborn** - Visualiza√ß√£o de dados
- **Requests** - Consumo da API TMDb
- **Jupyter Notebooks** - Desenvolvimento interativo
- **Ruff** - Linting e formata√ß√£o

## üîß Instala√ß√£o e Configura√ß√£o

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/Rhogger/feature-eng-and-ml.git
cd feature-eng-and-ml
```

### 2. Configure o ambiente virtual

Escolha uma das op√ß√µes abaixo:

#### Op√ß√£o A: Usando Pipenv (Recomendado)

```bash
# Instale o Pipenv (se n√£o tiver instalado)
pip install pipenv

# Instale as depend√™ncias
pipenv install

# Ative o ambiente virtual
pipenv shell
```

#### Op√ß√£o B: Usando venv

```bash
# Crie o ambiente virtual
python -m venv venv

# Ative o ambiente virtual
# Linux/Mac:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# Instale as depend√™ncias
pip install -r requirements.txt
```

### 3. Configure as vari√°veis de ambiente

1. Crie um arquivo `.env` na raiz do projeto:

```bash
# Crie o arquivo .env
touch .env
```

1. Adicione suas credenciais da API TMDb:

```env
TMDB_API_KEY=sua_chave_api_aqui
BASE_URL=https://api.themoviedb.org/3
```

> üí° **Como obter a chave da API TMDb:**
>
> 1. Acesse [TMDb](https://www.themoviedb.org/)
> 2. Crie uma conta gratuita
> 3. V√° em Configura√ß√µes > API
> 4. Solicite uma chave de API
> 5. Copie a chave e cole no arquivo `.env`

## üìÅ Estrutura do Projeto

```text
feature-eng-and-ml/
‚îú‚îÄ‚îÄ ia/                        # Modelos de IA e notebooks
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ constants/         # Constantes do projeto
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py   # Exporta todas as constantes
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ categorical_features.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ numerical_features.py
‚îÇ       ‚îú‚îÄ‚îÄ datasets/          # Datasets gerados pelos notebooks
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ movies.csv     # Dados brutos dos filmes
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_clean.csv # Dados limpos
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ eda.csv        # Dados ap√≥s EDA
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ model.csv      # Dados preparados para ML
‚îÇ       ‚îú‚îÄ‚îÄ models/            # Modelos treinados
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ model.pkl      # Modelo de classifica√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ notebooks/         # Jupyter Notebooks
‚îÇ           ‚îú‚îÄ‚îÄ get_data.ipynb      # 1. Coleta de dados
‚îÇ           ‚îú‚îÄ‚îÄ data_clean.ipynb    # 2. Limpeza de dados
‚îÇ           ‚îú‚îÄ‚îÄ eda.ipynb           # 3. An√°lise explorat√≥ria
‚îÇ           ‚îî‚îÄ‚îÄ model.ipynb         # 4. Treinamento do modelo
‚îú‚îÄ‚îÄ .vscode/                   # Configura√ß√µes do VS Code
‚îú‚îÄ‚îÄ .env                       # Vari√°veis de ambiente (criar manualmente)
‚îú‚îÄ‚îÄ .gitattributes            # Configura√ß√£o para diffs do Git
‚îú‚îÄ‚îÄ .gitignore                # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ Pipfile                   # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ Pipfile.lock              # Lock das depend√™ncias
‚îú‚îÄ‚îÄ ruff.toml                 # Configura√ß√£o do Ruff
‚îî‚îÄ‚îÄ README.md                 # Este arquivo
```

## üöÄ Como Executar o Projeto

### Pipeline de Execu√ß√£o dos Notebooks

O projeto segue uma pipeline sequencial onde cada notebook depende do anterior:

```mermaid
graph LR
    A[get_data.ipynb] --> B[data_clean.ipynb]
    B --> C[eda.ipynb]
    C --> D[model.ipynb]
```

#### 1. **get_data.ipynb** - Coleta de Dados

```bash
# Navegue para o diret√≥rio dos notebooks
cd ia/src/notebooks

# Execute o Jupyter Lab/Notebook
jupyter lab get_data.ipynb
```

**O que faz:**

- Conecta com a API do TMDb
- Coleta dados de filmes populares
- Cria o DataFrame inicial
- Gera o arquivo `movies.csv`

#### 2. **data_clean.ipynb** - Limpeza de Dados

```bash
jupyter lab data_clean.ipynb
```

**O que faz:**

- Carrega os dados brutos de `movies.csv`
- Aplica limpeza e tratamento de valores ausentes
- Realiza engenharia de features b√°sica
- Executa pipeline completo de ML
- Gera o arquivo `data_clean.csv`

#### 3. **eda.ipynb** - An√°lise Explorat√≥ria

```bash
jupyter lab eda.ipynb
```

**O que faz:**

- Carrega dados limpos de `data_clean.csv`
- Aplica engenharia de features avan√ßada
- Realiza an√°lise explorat√≥ria dos dados
- Prepara features para modelagem
- Gera o arquivo `eda.csv`

#### 4. **model.ipynb** - Treinamento do Modelo

```bash
jupyter lab model.ipynb
```

**O que faz:**

- Carrega dados preparados de `eda.csv`
- Treina modelo de classifica√ß√£o
- Avalia performance do modelo
- Salva modelo treinado em `model.pkl`
- Gera o arquivo `model.csv`

### Execu√ß√£o Completa da Pipeline

Para executar toda a pipeline de uma vez:

```bash
# 1. Ative o ambiente virtual
pipenv shell  # ou source venv/bin/activate

# 2. Navegue para o diret√≥rio dos notebooks
cd ia/src/notebooks

# 3. Execute os notebooks em sequ√™ncia
jupyter nbconvert --execute get_data.ipynb
jupyter nbconvert --execute data_clean.ipynb
jupyter nbconvert --execute eda.ipynb
jupyter nbconvert --execute model.ipynb
```

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

---
